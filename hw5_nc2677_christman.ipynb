{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMS-E6998-010: Homework 4 {-}\n",
    "__Name:__ Nicholas Christman (n2677)\n",
    "__Due:__ Nov. 22, 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f108fce7ed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# set global seed\n",
    "seed = 6998\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************\n",
      "GPU Available: True\n",
      "Current Device: cuda:0\n",
      "*************************\n",
      "\n",
      "Mon Nov 30 00:31:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   52C    P0    29W /  70W |     10MiB / 15079MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# use a GPU if there is one available\n",
    "cuda_availability = torch.cuda.is_available()\n",
    "if cuda_availability:\n",
    "    device = torch.device('cuda:{}'.format(torch.cuda.current_device()))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print('\\n*************************')\n",
    "print('GPU Available: {}'.format(cuda_availability))\n",
    "print('Current Device: {}'.format(device))\n",
    "print('*************************\\n')\n",
    "# display the GPU info\n",
    "if cuda_availability:\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - SSD, ONNX model, Visualization, Inferencing (35) {-}\n",
    "Following the github repo and ONNX tutorials (links provided below), start with a pretrained Pytorch SSD model and retrain it for your target categories, convert the Pytorch model to ONNX, and then deploy it on ONNX runtime server for inferencing.\n",
    "\n",
    "For part 1, 2, and 3, refer to the steps in the github repo. For part 4 refer to ONNX tutorial on visualizing and for 5 and 6 refer to ONNX tutorial on inferencing.  \n",
    "\n",
    "_References:_\n",
    "* Github repo. Shot MultiBox Detector Implementation in Pytorch.    \n",
    "Available at https://github.com/qfgaohao/pytorch-ssd\n",
    "* ONNX tutorial. Visualizing an ONNX Model.   \n",
    "Available at https://github.com/onnx/tutorials/blob/master/tutorials/VisualizingAModel.md\n",
    "* ONNX tutorial. Inferencing SSD ONNX model using ONNX Runtime Server.   \n",
    "Available at https://github.com/onnx/tutorials/blob/master/tutorials/OnnxRuntimeServerSSDModel.ipynb\n",
    "* Google. Open Images Dataset V5 + Extensions.   \n",
    "Available at https://storage.googleapis.com/openimages/web/index.html\n",
    "* The PASCAL Visual Object Classes Challenge 2007.   \n",
    "Available at http://host.robots.ox.ac.uk/pascal/VOC/voc2007/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Pretrained MobilenetV1 SSD tested locally with  Pascal VOC 2007 dataset (show the test accuracy for the 20 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-30 06:22:17--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
      "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
      "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 460032000 (439M) [application/x-tar]\n",
      "Saving to: ‘data/trainval/VOCtrainval_06-Nov-2007.tar’\n",
      "\n",
      "VOCtrainval_06-Nov- 100%[===================>] 438.72M  16.7MB/s    in 28s     \n",
      "\n",
      "2020-11-30 06:22:45 (15.7 MB/s) - ‘data/trainval/VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the trainval data\n",
    "# ! wget -P data/trainval http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "# ! tar -xf data/trainval/VOCtrainval_06-Nov-2007.tar -C data/trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-30 06:22:54--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
      "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
      "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 451020800 (430M) [application/x-tar]\n",
      "Saving to: ‘data/test/VOCtest_06-Nov-2007.tar’\n",
      "\n",
      "VOCtest_06-Nov-2007 100%[===================>] 430.13M  17.2MB/s    in 27s     \n",
      "\n",
      "2020-11-30 06:23:22 (15.8 MB/s) - ‘data/test/VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the  test data \n",
    "# ! wget -P data/test http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "# ! tar -xf data/test/VOCtest_06-Nov-2007.tar -C data/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-30 06:09:51--  https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 74.125.20.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37995286 (36M) [application/octet-stream]\n",
      "Saving to: ‘pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth’\n",
      "\n",
      "mobilenet-v1-ssd-mp 100%[===================>]  36.23M  73.0MB/s    in 0.5s    \n",
      "\n",
      "2020-11-30 06:09:52 (73.0 MB/s) - ‘pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth’ saved [37995286/37995286]\n",
      "\n",
      "--2020-11-30 06:09:52--  https://storage.googleapis.com/models-hao/voc-model-labels.txt\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.135.128, 74.125.142.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145 [text/plain]\n",
      "Saving to: ‘pytorch-ssd/models/voc-model-labels.txt’\n",
      "\n",
      "voc-model-labels.tx 100%[===================>]     145  --.-KB/s    in 0s      \n",
      "\n",
      "2020-11-30 06:09:52 (282 MB/s) - ‘pytorch-ssd/models/voc-model-labels.txt’ saved [145/145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the model/labels\n",
    "# ! wget -P pytorch-ssd/models https://storage.googleapis.com/models-hao/mobilenet-v1-ssd-mp-0_675.pth\n",
    "# ! wget -P pytorch-ssd/models https://storage.googleapis.com/models-hao/voc-model-labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model with Pascal VOC 2007 dataset\n",
    "# ! python pytorch-ssd/eval_ssd.py --net mb1-ssd \\\n",
    "# --dataset data/test/VOCdevkit/VOC2007/ \\\n",
    "# --trained_model pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth \\\n",
    "# --label_file pytorch-ssd/models/voc-model-labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: this is a snippet from the actual output._\n",
    "\n",
    "```\n",
    "pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
    "It took 0.0654754638671875 seconds to load the model.\n",
    "process image 0\n",
    "Load Image: 0.025498 seconds.\n",
    "Inference time:  0.8003177642822266\n",
    "Prediction: 0.859447 seconds.\n",
    "process image 1\n",
    "Load Image: 0.004779 seconds.\n",
    "Inference time:  0.007477521896362305\n",
    "Prediction: 0.059341 seconds.\n",
    "...\n",
    "process image 4950\n",
    "Load Image: 0.004848 seconds.\n",
    "Inference time:  0.005615711212158203\n",
    "Prediction: 0.037452 seconds.\n",
    "process image 4951\n",
    "Load Image: 0.005250 seconds.\n",
    "Inference time:  0.005333900451660156\n",
    "Prediction: 0.039187 seconds.\n",
    "\n",
    "\n",
    "Average Precision Per-class:\n",
    "aeroplane: 0.6742489426027927\n",
    "bicycle: 0.7913672875238116\n",
    "bird: 0.612096015101108\n",
    "boat: 0.5616402776942253\n",
    "bottle: 0.3471256662634949\n",
    "bus: 0.7742298893362103\n",
    "car: 0.7284171192326804\n",
    "cat: 0.8360675520354323\n",
    "chair: 0.5142295855384792\n",
    "cow: 0.6244090341627014\n",
    "diningtable: 0.7060035669312754\n",
    "dog: 0.7849252606216821\n",
    "horse: 0.8202146617282785\n",
    "motorbike: 0.793578272243471\n",
    "person: 0.7042670984734087\n",
    "pottedplant: 0.40257147509774405\n",
    "sheep: 0.6071252282334352\n",
    "sofa: 0.7549120254763918\n",
    "train: 0.8270992920206008\n",
    "tvmonitor: 0.6459903029666852\n",
    "\n",
    "Average Precision Across All Classes:0.6755259276641954\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Select two related categories from Google Open Images and finetune the pretrained SSD model. \n",
    "* Use _open_images_downloader.py_ script. \n",
    "* Use the same parameters that are used in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30 06:54:26,153 - root - Download https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv.\n",
      "2020-11-30 06:54:26,189 - root - Download https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv.\n",
      "2020-11-30 06:54:32,861 - root - Read annotation file data/trainval/open_images/train-annotations-bbox.csv\n",
      "2020-11-30 06:54:46,268 - root - train bounding boxes size: 1307\n",
      "2020-11-30 06:54:46,268 - root - Approximate Image Stats: \n",
      "2020-11-30 06:54:46,271 - root - Handgun: 561/990 = 0.57.\n",
      "2020-11-30 06:54:46,271 - root - Shotgun: 429/990 = 0.43.\n",
      "2020-11-30 06:54:46,271 - root - Label distribution: \n",
      "2020-11-30 06:54:46,272 - root - Handgun: 727/1307 = 0.56.\n",
      "2020-11-30 06:54:46,272 - root - Shotgun: 580/1307 = 0.44.\n",
      "2020-11-30 06:54:46,272 - root - Shuffle dataset.\n",
      "2020-11-30 06:54:46,272 - root - Save train data to data/trainval/open_images/sub-train-annotations-bbox.csv.\n",
      "2020-11-30 06:54:46,284 - root - Download https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv.\n",
      "2020-11-30 06:54:46,786 - root - Read annotation file data/trainval/open_images/validation-annotations-bbox.csv\n",
      "2020-11-30 06:54:47,003 - root - validation bounding boxes size: 50\n",
      "2020-11-30 06:54:47,004 - root - Approximate Image Stats: \n",
      "2020-11-30 06:54:47,006 - root - Handgun: 20/39 = 0.51.\n",
      "2020-11-30 06:54:47,006 - root - Shotgun: 19/39 = 0.49.\n",
      "2020-11-30 06:54:47,006 - root - Label distribution: \n",
      "2020-11-30 06:54:47,007 - root - Shotgun: 26/50 = 0.52.\n",
      "2020-11-30 06:54:47,007 - root - Handgun: 24/50 = 0.48.\n",
      "2020-11-30 06:54:47,007 - root - Shuffle dataset.\n",
      "2020-11-30 06:54:47,007 - root - Save validation data to data/trainval/open_images/sub-validation-annotations-bbox.csv.\n",
      "2020-11-30 06:54:47,008 - root - Download https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv.\n",
      "2020-11-30 06:54:47,986 - root - Read annotation file data/trainval/open_images/test-annotations-bbox.csv\n",
      "2020-11-30 06:54:48,599 - root - test bounding boxes size: 147\n",
      "2020-11-30 06:54:48,599 - root - Approximate Image Stats: \n",
      "2020-11-30 06:54:48,601 - root - Handgun: 72/130 = 0.55.\n",
      "2020-11-30 06:54:48,601 - root - Shotgun: 58/130 = 0.45.\n",
      "2020-11-30 06:54:48,601 - root - Label distribution: \n",
      "2020-11-30 06:54:48,602 - root - Handgun: 81/147 = 0.55.\n",
      "2020-11-30 06:54:48,602 - root - Shotgun: 66/147 = 0.45.\n",
      "2020-11-30 06:54:48,602 - root - Shuffle dataset.\n",
      "2020-11-30 06:54:48,602 - root - Save test data to data/trainval/open_images/sub-test-annotations-bbox.csv.\n",
      "2020-11-30 06:54:48,607 - root - Start downloading 1121 images.\n",
      "2020-11-30 06:54:50,402 - root - Downloaded 100 images.\n",
      "2020-11-30 06:54:51,459 - root - Downloaded 200 images.\n",
      "2020-11-30 06:54:52,485 - root - Downloaded 300 images.\n",
      "2020-11-30 06:54:53,520 - root - Downloaded 400 images.\n",
      "2020-11-30 06:54:54,549 - root - Downloaded 500 images.\n",
      "2020-11-30 06:54:55,596 - root - Downloaded 600 images.\n",
      "2020-11-30 06:54:56,632 - root - Downloaded 700 images.\n",
      "2020-11-30 06:54:57,689 - root - Downloaded 800 images.\n",
      "2020-11-30 06:54:58,796 - root - Downloaded 900 images.\n",
      "2020-11-30 06:55:00,558 - root - Downloaded 1000 images.\n",
      "2020-11-30 06:55:02,044 - root - Downloaded 1100 images.\n",
      "2020-11-30 06:55:03,018 - root - Task Done.\n"
     ]
    }
   ],
   "source": [
    "# getting the Google Open Image data\n",
    "! python pytorch-ssd/open_images_downloader.py --root data/trainval/open_images \\\n",
    "                                               --class_names \"Handgun,Shotgun\" \\\n",
    "                                               --num_workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-30 06:59:05--  https://storage.googleapis.com/models-hao/gun_model_2.21.pth\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.142.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 27044080 (26M) [application/octet-stream]\n",
      "Saving to: ‘pytorch-ssd/models/gun_model_2.21.pth’\n",
      "\n",
      "gun_model_2.21.pth  100%[===================>]  25.79M  64.6MB/s    in 0.4s    \n",
      "\n",
      "2020-11-30 06:59:06 (64.6 MB/s) - ‘pytorch-ssd/models/gun_model_2.21.pth’ saved [27044080/27044080]\n",
      "\n",
      "--2020-11-30 06:59:06--  https://storage.googleapis.com/models-hao/open-images-model-labels.txt\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.197.128, 74.125.142.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26 [text/plain]\n",
      "Saving to: ‘pytorch-ssd/models/open-images-model-labels.txt’\n",
      "\n",
      "open-images-model-l 100%[===================>]      26  --.-KB/s    in 0s      \n",
      "\n",
      "2020-11-30 06:59:07 (41.5 MB/s) - ‘pytorch-ssd/models/open-images-model-labels.txt’ saved [26/26]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the Open Image models\n",
    "! wget -P pytorch-ssd/models https://storage.googleapis.com/models-hao/gun_model_2.21.pth\n",
    "! wget -P pytorch-ssd/models https://storage.googleapis.com/models-hao/open-images-model-labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-30 07:06:51,518 - root - INFO - Use Cuda.\n",
      "2020-11-30 07:06:51,518 - root - INFO - Namespace(balance_data=False, base_net=None, base_net_lr=0.001, batch_size=5, checkpoint_folder='pytorch-ssd/models', dataset_type='open_images', datasets=['data/trainval/open_images'], debug_steps=100, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, lr=0.01, mb2_width_mult=1.0, milestones='80,100', momentum=0.9, net='mb1-ssd', num_epochs=2, num_workers=4, pretrained_ssd='pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', t_max=100.0, use_cuda=True, validation_dataset=None, validation_epochs=5, weight_decay=0.0005)\n",
      "2020-11-30 07:06:51,519 - root - INFO - Prepare training datasets.\n",
      "2020-11-30 07:06:52,101 - root - INFO - Dataset Summary:Number of Images: 961\n",
      "Minimum Number of Images for a Class: -1\n",
      "Label Distribution:\n",
      "\tHandgun: 727\n",
      "\tShotgun: 580\n",
      "2020-11-30 07:06:52,102 - root - INFO - Stored labels into file pytorch-ssd/models/open-images-model-labels.txt.\n",
      "2020-11-30 07:06:52,103 - root - INFO - Train dataset size: 961\n",
      "2020-11-30 07:06:52,103 - root - INFO - Prepare Validation datasets.\n",
      "2020-11-30 07:06:52,187 - root - INFO - Dataset Summary:Number of Images: 123\n",
      "Minimum Number of Images for a Class: -1\n",
      "Label Distribution:\n",
      "\tHandgun: 81\n",
      "\tShotgun: 66\n",
      "2020-11-30 07:06:52,188 - root - INFO - validation dataset size: 123\n",
      "2020-11-30 07:06:52,188 - root - INFO - Build network.\n",
      "2020-11-30 07:06:52,276 - root - INFO - Init from pretrained ssd pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth\n",
      "2020-11-30 07:06:52,317 - root - INFO - Took 0.04 seconds to load the model.\n",
      "2020-11-30 07:06:55,243 - root - INFO - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
      "2020-11-30 07:06:55,243 - root - INFO - Uses CosineAnnealingLR scheduler.\n",
      "2020-11-30 07:06:55,244 - root - INFO - Start training from epoch 0.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"pytorch-ssd/train_ssd.py\", line 326, in <module>\n",
      "    device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)\n",
      "  File \"pytorch-ssd/train_ssd.py\", line 116, in train\n",
      "    for i, data in enumerate(loader):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 808, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# finetune the SSD model for the new data\n",
    "# ! cd pytorch-ssd\n",
    "! python pytorch-ssd/train_ssd.py --dataset_type open_images \\\n",
    "                      --datasets data/trainval/open_images \\\n",
    "                      --net mb1-ssd \\\n",
    "                      --pretrained_ssd pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth \\\n",
    "                      --checkpoint_folder pytorch-ssd/models \\\n",
    "                      --scheduler cosine \\\n",
    "                      --lr 0.01 \\\n",
    "                      --t_max 100 \\\n",
    "                      --validation_epochs 5 \\\n",
    "                      --num_epochs 2 \\\n",
    "                      --base_net_lr 0.001 \\\n",
    "                      --batch_size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"pytorch-ssd/convert_to_caffe2_models.py\", line 47, in <module>\n",
      "    torch.onnx.export(net, dummy_input, model_path, verbose=False, output_names=['scores', 'boxes'])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/onnx/__init__.py\", line 148, in export\n",
      "    strip_doc_string, dynamic_axes, keep_initializers_as_inputs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py\", line 66, in export\n",
      "    dynamic_axes=dynamic_axes, keep_initializers_as_inputs=keep_initializers_as_inputs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py\", line 416, in _export\n",
      "    fixed_batch_size=fixed_batch_size)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py\", line 279, in _model_to_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args, training)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/onnx/utils.py\", line 236, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(model, args, _force_outplace=True, _return_inputs_states=True)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/jit/__init__.py\", line 277, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/jit/__init__.py\", line 360, in forward\n",
      "    self._force_outplace,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/jit/__init__.py\", line 347, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 530, in __call__\n",
      "    result = self._slow_forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 516, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/jupyter/comse6998-hw5/pytorch-ssd/vision/ssd/ssd.py\", line 93, in forward\n",
      "    locations, self.priors, self.config.center_variance, self.config.size_variance\n",
      "  File \"/home/jupyter/comse6998-hw5/pytorch-ssd/vision/utils/box_utils.py\", line 104, in convert_locations_to_boxes\n",
      "    locations[..., :2] * center_variance * priors[..., 2:] + priors[..., :2],\n",
      "RuntimeError: expected device cpu but got device cuda:0\n"
     ]
    }
   ],
   "source": [
    "# convert the models to ONNX format\n",
    "! python pytorch-ssd/convert_to_caffe2_models.py \\\n",
    "                    mb1-ssd pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth \\\n",
    "                    pytorch-ssd/models/voc-model-labels.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
